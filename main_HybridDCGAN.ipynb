{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d9278f2",
   "metadata": {},
   "source": [
    "Three Hidden Layers in both Classical Discriminator and Quantum Generator\n",
    "\n",
    "main_lat_10_mid_4_8_16_size_16_13_10_4_1_class0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87d1b0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('./QuantumGAN_utils')\n",
    "from DataLoading import MNIST_DataLoading\n",
    "from new_QGAN_threeMid_add_lastBN import QuantumGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bde3e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "mySeed = 100\n",
    "random.seed(mySeed)\n",
    "np.random.seed(mySeed)\n",
    "torch.manual_seed(mySeed)\n",
    "torch.use_deterministic_algorithms(True) # Needed for reproducible results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8a21263",
   "metadata": {},
   "source": [
    "# Setting & Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f80b828",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_size = 20 \n",
    "batch_size = 64\n",
    "\n",
    "lr_D = 0.0005\n",
    "lr_G = 0.005\n",
    "\n",
    "\n",
    "KernelAncilla = 0\n",
    "N_layer = 10\n",
    "\n",
    "\n",
    "# Classical Discriminator\n",
    "final_dim = 1\n",
    "final_size = (1,1)\n",
    "\n",
    "\n",
    "# Quantum Generator\n",
    "\n",
    "latent_dim = 10\n",
    "latent_size = (1,1)\n",
    "kernel_size_4 = (4,4)\n",
    "\n",
    "\n",
    "middle_dim_3 = 16\n",
    "middle_size_3 = (4,4)\n",
    "kernel_size_3 = (7,7)\n",
    "\n",
    "\n",
    "middle_dim_2 = 8\n",
    "middle_size_2 = (10,10)\n",
    "kernel_size_2 = (4,4)\n",
    "\n",
    "\n",
    "middle_dim_1 = 4\n",
    "middle_size_1 = (13,13)\n",
    "kernel_size_1 = (4,4)\n",
    "\n",
    "\n",
    "image_dim = 1\n",
    "image_size = (16,16)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "646b7058",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "saving_path = \"QGAN_ClassicalDis_lat_{0}_size_16_13_10_4_1\".format(latent_dim)\n",
    "\n",
    "\n",
    "image_file = \"./{0}/image/mid_{1}_{2}_{3}\".format(saving_path, middle_dim_1, middle_dim_2, middle_dim_3)\n",
    "ckpt_file = \"./{0}/ckpt/mid_{1}_{2}_{3}\".format(saving_path, middle_dim_1, middle_dim_2, middle_dim_3)\n",
    "\n",
    "os.makedirs(image_file, exist_ok=True)\n",
    "os.makedirs(ckpt_file, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "discriminator_tensor = \"./{0}/discriminator_tensor/mid_{1}_{2}_{3}\".format(saving_path, middle_dim_1, middle_dim_2, middle_dim_3)\n",
    "generator_tensor = \"./{0}/generator_tensor/mid_{1}_{2}_{3}\".format(saving_path, middle_dim_1, middle_dim_2, middle_dim_3)\n",
    "\n",
    "os.makedirs(discriminator_tensor, exist_ok=True)\n",
    "os.makedirs(generator_tensor, exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b3b0653",
   "metadata": {},
   "source": [
    "# DataLoading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8900d881",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader , train_dataset, test_dataset = MNIST_DataLoading(saving_location=\"./mnist\", image_size=image_size[0], \n",
    "                                                                            batch_size=batch_size, data_label=[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "097ce15f",
   "metadata": {},
   "source": [
    "# Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(1, middle_dim_1, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(middle_dim_1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(middle_dim_1, middle_dim_2, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(middle_dim_2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(middle_dim_2, middle_dim_3, 7, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(middle_dim_3),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(middle_dim_3, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        return self.main(input)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9452f78e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "# -------------------------------- Discriminator: 1*16*16 --> 4*13*13 --> 8*10*10 --> 16*4*4 --> 1*1*1 --------------------------------\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "\n",
    "# -------------------------------- Generator: 10*1*1 --> 16*4*4 --> 8*10*10 --> 4*13*13 --> 1*16*16 --------------------------------\n",
    "generator = QuantumGenerator(KernelAncilla=KernelAncilla, layer_num=N_layer, \n",
    "                             stage_1_dim=latent_dim, stage_1_input_size=latent_size, \n",
    "                             stage_1_kernel_size=kernel_size_4,stage_1_stride=1, stage_1_padding=3,\n",
    "                             stage_2_dim=middle_dim_3, stage_2_input_size=middle_size_3, \n",
    "                             stage_2_kernel_size=kernel_size_3,stage_2_stride=1, stage_2_padding=6,  \n",
    "                             stage_3_dim=middle_dim_2, stage_3_input_size=middle_size_2, \n",
    "                             stage_3_kernel_size=kernel_size_2,stage_3_stride=1, stage_3_padding=3, \n",
    "                             stage_4_dim=middle_dim_1, stage_4_input_size=middle_size_1, \n",
    "                             stage_4_kernel_size=kernel_size_1,stage_4_stride=1, stage_4_padding=3, \n",
    "                             final_dim=image_dim, final_size=image_size).to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(1, 4, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (3): Conv2d(4, 8, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(8, 16, kernel_size=(7, 7), stride=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (9): Conv2d(16, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 4, 13, 13]              64\n",
      "       BatchNorm2d-2            [-1, 4, 13, 13]               8\n",
      "         LeakyReLU-3            [-1, 4, 13, 13]               0\n",
      "            Conv2d-4            [-1, 8, 10, 10]             512\n",
      "       BatchNorm2d-5            [-1, 8, 10, 10]              16\n",
      "         LeakyReLU-6            [-1, 8, 10, 10]               0\n",
      "            Conv2d-7             [-1, 16, 4, 4]           6,272\n",
      "       BatchNorm2d-8             [-1, 16, 4, 4]              32\n",
      "         LeakyReLU-9             [-1, 16, 4, 4]               0\n",
      "           Conv2d-10              [-1, 1, 1, 1]             256\n",
      "          Sigmoid-11              [-1, 1, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 7,160\n",
      "Trainable params: 7,160\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 0.07\n",
      "----------------------------------------------------------------\n",
      "QuantumGenerator(\n",
      "  (BatchNorm2d_stage_2_dim): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (BatchNorm2d_stage_3_dim): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (BatchNorm2d_stage_4_dim): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (BatchNorm2d_final_dim): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (ReLU): ReLU(inplace=True)\n",
      "  (Tanh): Tanh()\n",
      "  (qgen_stage_1): Sequential(\n",
      "    (0): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (1): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (2): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (3): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (4): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (5): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (6): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (7): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (8): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (9): <Quantum Torch Layer: func=qcnn_node>\n",
      "  )\n",
      "  (qgen_stage_2): Sequential(\n",
      "    (0): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (1): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (2): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (3): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (4): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (5): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (6): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (7): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (8): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (9): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (10): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (11): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (12): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (13): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (14): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (15): <Quantum Torch Layer: func=qcnn_node>\n",
      "  )\n",
      "  (qgen_stage_3): Sequential(\n",
      "    (0): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (1): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (2): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (3): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (4): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (5): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (6): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (7): <Quantum Torch Layer: func=qcnn_node>\n",
      "  )\n",
      "  (qgen_stage_4): Sequential(\n",
      "    (0): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (1): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (2): <Quantum Torch Layer: func=qcnn_node>\n",
      "    (3): <Quantum Torch Layer: func=qcnn_node>\n",
      "  )\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "        TorchLayer-1                  [-1, 512]               0\n",
      "        TorchLayer-2                  [-1, 512]               0\n",
      "        TorchLayer-3                  [-1, 512]               0\n",
      "        TorchLayer-4                  [-1, 512]               0\n",
      "        TorchLayer-5                  [-1, 512]               0\n",
      "        TorchLayer-6                  [-1, 512]               0\n",
      "        TorchLayer-7                  [-1, 512]               0\n",
      "        TorchLayer-8                  [-1, 512]               0\n",
      "        TorchLayer-9                  [-1, 512]               0\n",
      "       TorchLayer-10                  [-1, 512]               0\n",
      "      BatchNorm2d-11             [-1, 16, 4, 4]              32\n",
      "             ReLU-12             [-1, 16, 4, 4]               0\n",
      "       TorchLayer-13                [-1, 16384]               0\n",
      "       TorchLayer-14                [-1, 16384]               0\n",
      "       TorchLayer-15                [-1, 16384]               0\n",
      "       TorchLayer-16                [-1, 16384]               0\n",
      "       TorchLayer-17                [-1, 16384]               0\n",
      "       TorchLayer-18                [-1, 16384]               0\n",
      "       TorchLayer-19                [-1, 16384]               0\n",
      "       TorchLayer-20                [-1, 16384]               0\n",
      "       TorchLayer-21                [-1, 16384]               0\n",
      "       TorchLayer-22                [-1, 16384]               0\n",
      "       TorchLayer-23                [-1, 16384]               0\n",
      "       TorchLayer-24                [-1, 16384]               0\n",
      "       TorchLayer-25                [-1, 16384]               0\n",
      "       TorchLayer-26                [-1, 16384]               0\n",
      "       TorchLayer-27                [-1, 16384]               0\n",
      "       TorchLayer-28                [-1, 16384]               0\n",
      "      BatchNorm2d-29            [-1, 8, 10, 10]              16\n",
      "             ReLU-30            [-1, 8, 10, 10]               0\n",
      "       TorchLayer-31                 [-1, 8192]               0\n",
      "       TorchLayer-32                 [-1, 8192]               0\n",
      "       TorchLayer-33                 [-1, 8192]               0\n",
      "       TorchLayer-34                 [-1, 8192]               0\n",
      "       TorchLayer-35                 [-1, 8192]               0\n",
      "       TorchLayer-36                 [-1, 8192]               0\n",
      "       TorchLayer-37                 [-1, 8192]               0\n",
      "       TorchLayer-38                 [-1, 8192]               0\n",
      "      BatchNorm2d-39            [-1, 4, 13, 13]               8\n",
      "             ReLU-40            [-1, 4, 13, 13]               0\n",
      "       TorchLayer-41                 [-1, 8192]               0\n",
      "       TorchLayer-42                 [-1, 8192]               0\n",
      "       TorchLayer-43                 [-1, 8192]               0\n",
      "       TorchLayer-44                 [-1, 8192]               0\n",
      "      BatchNorm2d-45            [-1, 1, 16, 16]               2\n",
      "             Tanh-46            [-1, 1, 16, 16]               0\n",
      "================================================================\n",
      "Total params: 58\n",
      "Trainable params: 58\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 2.82\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 2.82\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(discriminator)\n",
    "summary(discriminator, (1,16,16))\n",
    "\n",
    "print(generator)\n",
    "summary(generator, (latent_dim,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de513754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator.load_state_dict(torch.load('./ckpt/mid_4/1/discriminator_8_0.pt'))\n",
    "# generator.load_state_dict(torch.load('./ckpt/mid_4/1/generator_8_0.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2b101bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Optimizer\n",
    "b1 = 0.5\n",
    "b2 = 0.999\n",
    "opt_D = optim.Adam(discriminator.parameters(), lr=lr_D, betas=(b1, b2))\n",
    "opt_G = optim.Adam(generator.parameters(), lr=lr_G, betas=(b1, b2))\n",
    "\n",
    "# Label\n",
    "real_label = torch.full((batch_size,), 1.0, dtype=torch.float32).to(device)\n",
    "fake_label = torch.full((batch_size,), 0.0, dtype=torch.float32).to(device)\n",
    "\n",
    "# Testing Noise\n",
    "fixed_noise = torch.randn(64, latent_dim, 1, 1, device=device).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03c8d427",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1556e6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/20] [Batch 0/92] [D loss: 1.478825330734253] [G loss: 0.7675439119338989]\n",
      "saved images and state\n",
      "[Epoch 0/20] [Batch 10/92] [D loss: 0.9659445285797119] [G loss: 0.8994162678718567]\n",
      "saved images and state\n",
      "[Epoch 0/20] [Batch 20/92] [D loss: 0.9473181366920471] [G loss: 0.9160370826721191]\n",
      "saved images and state\n",
      "[Epoch 0/20] [Batch 30/92] [D loss: 0.9179482460021973] [G loss: 1.1494485139846802]\n",
      "saved images and state\n",
      "[Epoch 0/20] [Batch 40/92] [D loss: 1.1194690465927124] [G loss: 0.9893391132354736]\n",
      "saved images and state\n",
      "[Epoch 0/20] [Batch 50/92] [D loss: 0.9693689942359924] [G loss: 1.1957731246948242]\n",
      "saved images and state\n",
      "[Epoch 0/20] [Batch 60/92] [D loss: 0.9932500123977661] [G loss: 1.2388792037963867]\n",
      "saved images and state\n",
      "[Epoch 0/20] [Batch 70/92] [D loss: 0.816138744354248] [G loss: 1.44775390625]\n",
      "saved images and state\n",
      "[Epoch 0/20] [Batch 80/92] [D loss: 0.8229727745056152] [G loss: 1.430643081665039]\n",
      "saved images and state\n",
      "[Epoch 0/20] [Batch 90/92] [D loss: 0.9412750005722046] [G loss: 1.5155260562896729]\n",
      "saved images and state\n",
      "[Epoch 1/20] [Batch 0/92] [D loss: 0.7667948603630066] [G loss: 1.5796005725860596]\n",
      "saved images and state\n",
      "[Epoch 1/20] [Batch 10/92] [D loss: 1.0356382131576538] [G loss: 1.2510169744491577]\n",
      "saved images and state\n",
      "[Epoch 1/20] [Batch 20/92] [D loss: 1.0338516235351562] [G loss: 1.4066293239593506]\n",
      "saved images and state\n",
      "[Epoch 1/20] [Batch 30/92] [D loss: 1.3992879390716553] [G loss: 1.193075180053711]\n",
      "saved images and state\n",
      "[Epoch 1/20] [Batch 40/92] [D loss: 0.7414804697036743] [G loss: 1.5827432870864868]\n",
      "saved images and state\n",
      "[Epoch 1/20] [Batch 50/92] [D loss: 1.3493499755859375] [G loss: 1.2580045461654663]\n",
      "saved images and state\n",
      "[Epoch 1/20] [Batch 60/92] [D loss: 1.1467666625976562] [G loss: 1.5263071060180664]\n",
      "saved images and state\n",
      "[Epoch 1/20] [Batch 70/92] [D loss: 1.1624877452850342] [G loss: 1.5327463150024414]\n",
      "saved images and state\n",
      "[Epoch 1/20] [Batch 80/92] [D loss: 0.5722224116325378] [G loss: 2.290703296661377]\n",
      "saved images and state\n",
      "[Epoch 1/20] [Batch 90/92] [D loss: 0.7783348560333252] [G loss: 1.6676968336105347]\n",
      "saved images and state\n",
      "[Epoch 2/20] [Batch 0/92] [D loss: 0.8115031123161316] [G loss: 1.6870501041412354]\n",
      "saved images and state\n",
      "[Epoch 2/20] [Batch 10/92] [D loss: 1.086590051651001] [G loss: 1.36008882522583]\n",
      "saved images and state\n",
      "[Epoch 2/20] [Batch 20/92] [D loss: 1.0242087841033936] [G loss: 1.4724819660186768]\n",
      "saved images and state\n",
      "[Epoch 2/20] [Batch 30/92] [D loss: 0.6444320678710938] [G loss: 1.7502810955047607]\n",
      "saved images and state\n",
      "[Epoch 2/20] [Batch 40/92] [D loss: 0.7902572154998779] [G loss: 1.659022569656372]\n",
      "saved images and state\n",
      "[Epoch 2/20] [Batch 50/92] [D loss: 1.123342514038086] [G loss: 1.2192775011062622]\n",
      "saved images and state\n",
      "[Epoch 2/20] [Batch 60/92] [D loss: 1.1448863744735718] [G loss: 1.420121431350708]\n",
      "saved images and state\n",
      "[Epoch 2/20] [Batch 70/92] [D loss: 0.9296813607215881] [G loss: 1.436869740486145]\n",
      "saved images and state\n",
      "[Epoch 2/20] [Batch 80/92] [D loss: 0.9888243675231934] [G loss: 1.2473151683807373]\n",
      "saved images and state\n",
      "[Epoch 2/20] [Batch 90/92] [D loss: 1.09100341796875] [G loss: 1.259504795074463]\n",
      "saved images and state\n",
      "[Epoch 3/20] [Batch 0/92] [D loss: 0.9776215553283691] [G loss: 1.481619119644165]\n",
      "saved images and state\n",
      "[Epoch 3/20] [Batch 10/92] [D loss: 1.0860176086425781] [G loss: 1.2293684482574463]\n",
      "saved images and state\n",
      "[Epoch 3/20] [Batch 20/92] [D loss: 1.0482776165008545] [G loss: 1.235778570175171]\n",
      "saved images and state\n",
      "[Epoch 3/20] [Batch 30/92] [D loss: 0.962247908115387] [G loss: 1.1960779428482056]\n",
      "saved images and state\n",
      "[Epoch 3/20] [Batch 40/92] [D loss: 1.1332643032073975] [G loss: 1.1228622198104858]\n",
      "saved images and state\n",
      "[Epoch 3/20] [Batch 50/92] [D loss: 1.148429274559021] [G loss: 1.2179896831512451]\n",
      "saved images and state\n",
      "[Epoch 3/20] [Batch 60/92] [D loss: 1.012923002243042] [G loss: 1.2545058727264404]\n",
      "saved images and state\n",
      "[Epoch 3/20] [Batch 70/92] [D loss: 1.0365996360778809] [G loss: 1.1611018180847168]\n",
      "saved images and state\n",
      "[Epoch 3/20] [Batch 80/92] [D loss: 1.0443065166473389] [G loss: 1.1616628170013428]\n",
      "saved images and state\n",
      "[Epoch 3/20] [Batch 90/92] [D loss: 1.0839815139770508] [G loss: 1.1278066635131836]\n",
      "saved images and state\n",
      "[Epoch 4/20] [Batch 0/92] [D loss: 1.091354489326477] [G loss: 1.0888867378234863]\n",
      "saved images and state\n",
      "[Epoch 4/20] [Batch 10/92] [D loss: 1.0381577014923096] [G loss: 1.0840387344360352]\n",
      "saved images and state\n",
      "[Epoch 4/20] [Batch 20/92] [D loss: 0.9068435430526733] [G loss: 1.1985222101211548]\n",
      "saved images and state\n",
      "[Epoch 4/20] [Batch 30/92] [D loss: 0.9854326248168945] [G loss: 1.149763822555542]\n",
      "saved images and state\n",
      "[Epoch 4/20] [Batch 40/92] [D loss: 0.9705905318260193] [G loss: 1.1996949911117554]\n",
      "saved images and state\n",
      "[Epoch 4/20] [Batch 50/92] [D loss: 0.8850126266479492] [G loss: 1.3356505632400513]\n",
      "saved images and state\n",
      "[Epoch 4/20] [Batch 60/92] [D loss: 0.9138164520263672] [G loss: 1.2048604488372803]\n",
      "saved images and state\n",
      "[Epoch 4/20] [Batch 70/92] [D loss: 0.9608011841773987] [G loss: 1.1658809185028076]\n",
      "saved images and state\n",
      "[Epoch 4/20] [Batch 80/92] [D loss: 1.0253324508666992] [G loss: 1.0025687217712402]\n",
      "saved images and state\n",
      "[Epoch 4/20] [Batch 90/92] [D loss: 0.8666329383850098] [G loss: 1.2983280420303345]\n",
      "saved images and state\n",
      "[Epoch 5/20] [Batch 0/92] [D loss: 0.8573199510574341] [G loss: 1.4568767547607422]\n",
      "saved images and state\n",
      "[Epoch 5/20] [Batch 10/92] [D loss: 0.8464994430541992] [G loss: 1.440225601196289]\n",
      "saved images and state\n",
      "[Epoch 5/20] [Batch 20/92] [D loss: 0.7707993388175964] [G loss: 1.4946361780166626]\n",
      "saved images and state\n",
      "[Epoch 5/20] [Batch 30/92] [D loss: 0.8355344533920288] [G loss: 1.5775138139724731]\n",
      "saved images and state\n",
      "[Epoch 5/20] [Batch 40/92] [D loss: 0.802215576171875] [G loss: 1.216578722000122]\n",
      "saved images and state\n",
      "[Epoch 5/20] [Batch 50/92] [D loss: 0.7511169910430908] [G loss: 1.4380033016204834]\n",
      "saved images and state\n",
      "[Epoch 5/20] [Batch 60/92] [D loss: 0.8182708024978638] [G loss: 1.6618669033050537]\n",
      "saved images and state\n",
      "[Epoch 5/20] [Batch 70/92] [D loss: 0.7353875637054443] [G loss: 1.3380478620529175]\n",
      "saved images and state\n",
      "[Epoch 5/20] [Batch 80/92] [D loss: 0.8370923399925232] [G loss: 1.4199000597000122]\n",
      "saved images and state\n",
      "[Epoch 5/20] [Batch 90/92] [D loss: 0.8984000086784363] [G loss: 1.3404908180236816]\n",
      "saved images and state\n",
      "[Epoch 6/20] [Batch 0/92] [D loss: 0.6967328786849976] [G loss: 1.823679804801941]\n",
      "saved images and state\n",
      "[Epoch 6/20] [Batch 10/92] [D loss: 0.7107921838760376] [G loss: 1.6656138896942139]\n",
      "saved images and state\n",
      "[Epoch 6/20] [Batch 20/92] [D loss: 0.6677755117416382] [G loss: 1.3875343799591064]\n",
      "saved images and state\n",
      "[Epoch 6/20] [Batch 30/92] [D loss: 0.9290072321891785] [G loss: 0.9137154817581177]\n",
      "saved images and state\n",
      "[Epoch 6/20] [Batch 40/92] [D loss: 0.7796353101730347] [G loss: 1.8601349592208862]\n",
      "saved images and state\n",
      "[Epoch 6/20] [Batch 50/92] [D loss: 0.5883173942565918] [G loss: 1.80715012550354]\n",
      "saved images and state\n",
      "[Epoch 6/20] [Batch 60/92] [D loss: 0.7761590480804443] [G loss: 1.6032954454421997]\n",
      "saved images and state\n",
      "[Epoch 6/20] [Batch 70/92] [D loss: 0.5960441827774048] [G loss: 1.7134313583374023]\n",
      "saved images and state\n",
      "[Epoch 6/20] [Batch 80/92] [D loss: 0.8070964813232422] [G loss: 1.53089439868927]\n",
      "saved images and state\n",
      "[Epoch 6/20] [Batch 90/92] [D loss: 0.6350950002670288] [G loss: 1.7339739799499512]\n",
      "saved images and state\n",
      "[Epoch 7/20] [Batch 0/92] [D loss: 0.758039116859436] [G loss: 1.426278829574585]\n",
      "saved images and state\n",
      "[Epoch 7/20] [Batch 10/92] [D loss: 0.7570034861564636] [G loss: 1.3853623867034912]\n",
      "saved images and state\n",
      "[Epoch 7/20] [Batch 20/92] [D loss: 0.6750088930130005] [G loss: 1.5893301963806152]\n",
      "saved images and state\n",
      "[Epoch 7/20] [Batch 30/92] [D loss: 0.6921684741973877] [G loss: 1.6724488735198975]\n",
      "saved images and state\n",
      "[Epoch 7/20] [Batch 40/92] [D loss: 0.6472719311714172] [G loss: 1.5996575355529785]\n",
      "saved images and state\n",
      "[Epoch 7/20] [Batch 50/92] [D loss: 0.7402316927909851] [G loss: 1.3486090898513794]\n",
      "saved images and state\n",
      "[Epoch 7/20] [Batch 60/92] [D loss: 0.8414337635040283] [G loss: 1.4266581535339355]\n",
      "saved images and state\n",
      "[Epoch 7/20] [Batch 70/92] [D loss: 0.8251202702522278] [G loss: 2.137890338897705]\n",
      "saved images and state\n",
      "[Epoch 7/20] [Batch 80/92] [D loss: 0.7923873662948608] [G loss: 1.4270949363708496]\n",
      "saved images and state\n",
      "[Epoch 7/20] [Batch 90/92] [D loss: 0.7767688035964966] [G loss: 1.5382015705108643]\n",
      "saved images and state\n",
      "[Epoch 8/20] [Batch 0/92] [D loss: 0.7291263937950134] [G loss: 1.6722723245620728]\n",
      "saved images and state\n",
      "[Epoch 8/20] [Batch 10/92] [D loss: 0.8096644878387451] [G loss: 2.350084066390991]\n",
      "saved images and state\n",
      "[Epoch 8/20] [Batch 20/92] [D loss: 0.8567372560501099] [G loss: 1.6073200702667236]\n",
      "saved images and state\n",
      "[Epoch 8/20] [Batch 30/92] [D loss: 0.8351248502731323] [G loss: 1.5488810539245605]\n",
      "saved images and state\n",
      "[Epoch 8/20] [Batch 40/92] [D loss: 0.886367917060852] [G loss: 1.3653509616851807]\n",
      "saved images and state\n",
      "[Epoch 8/20] [Batch 50/92] [D loss: 0.802528977394104] [G loss: 1.664815902709961]\n",
      "saved images and state\n",
      "[Epoch 8/20] [Batch 60/92] [D loss: 0.7522071599960327] [G loss: 1.4186592102050781]\n",
      "saved images and state\n",
      "[Epoch 8/20] [Batch 70/92] [D loss: 0.6266859769821167] [G loss: 1.7006194591522217]\n",
      "saved images and state\n",
      "[Epoch 8/20] [Batch 80/92] [D loss: 0.8232871294021606] [G loss: 1.8089258670806885]\n",
      "saved images and state\n",
      "[Epoch 8/20] [Batch 90/92] [D loss: 0.8238142728805542] [G loss: 1.1299793720245361]\n",
      "saved images and state\n",
      "[Epoch 9/20] [Batch 0/92] [D loss: 0.8635539412498474] [G loss: 1.3513319492340088]\n",
      "saved images and state\n",
      "[Epoch 9/20] [Batch 10/92] [D loss: 0.6008630394935608] [G loss: 1.7153323888778687]\n",
      "saved images and state\n",
      "[Epoch 9/20] [Batch 20/92] [D loss: 0.6739228963851929] [G loss: 1.6845943927764893]\n",
      "saved images and state\n",
      "[Epoch 9/20] [Batch 30/92] [D loss: 0.7571358680725098] [G loss: 1.3188612461090088]\n",
      "saved images and state\n",
      "[Epoch 9/20] [Batch 40/92] [D loss: 0.6378684639930725] [G loss: 1.5290305614471436]\n",
      "saved images and state\n",
      "[Epoch 9/20] [Batch 50/92] [D loss: 0.6515604853630066] [G loss: 1.7016011476516724]\n",
      "saved images and state\n",
      "[Epoch 9/20] [Batch 60/92] [D loss: 0.7765875458717346] [G loss: 2.191972255706787]\n",
      "saved images and state\n",
      "[Epoch 9/20] [Batch 70/92] [D loss: 0.6689385175704956] [G loss: 1.500478744506836]\n",
      "saved images and state\n",
      "[Epoch 9/20] [Batch 80/92] [D loss: 0.7588685750961304] [G loss: 1.4003269672393799]\n",
      "saved images and state\n",
      "[Epoch 9/20] [Batch 90/92] [D loss: 0.5677496194839478] [G loss: 2.018544912338257]\n",
      "saved images and state\n",
      "[Epoch 10/20] [Batch 0/92] [D loss: 0.8609738945960999] [G loss: 2.084726333618164]\n",
      "saved images and state\n",
      "[Epoch 10/20] [Batch 10/92] [D loss: 0.780437171459198] [G loss: 1.603535771369934]\n",
      "saved images and state\n",
      "[Epoch 10/20] [Batch 20/92] [D loss: 0.6913365721702576] [G loss: 1.3629944324493408]\n",
      "saved images and state\n",
      "[Epoch 10/20] [Batch 30/92] [D loss: 0.7505728006362915] [G loss: 1.5835226774215698]\n",
      "saved images and state\n",
      "[Epoch 10/20] [Batch 40/92] [D loss: 0.7199820280075073] [G loss: 1.2069889307022095]\n",
      "saved images and state\n",
      "[Epoch 10/20] [Batch 50/92] [D loss: 0.5846408605575562] [G loss: 1.8185803890228271]\n",
      "saved images and state\n",
      "[Epoch 10/20] [Batch 60/92] [D loss: 0.6788197755813599] [G loss: 1.1704463958740234]\n",
      "saved images and state\n",
      "[Epoch 10/20] [Batch 70/92] [D loss: 0.6661136150360107] [G loss: 1.9548182487487793]\n",
      "saved images and state\n",
      "[Epoch 10/20] [Batch 80/92] [D loss: 0.6184650659561157] [G loss: 1.5486022233963013]\n",
      "saved images and state\n",
      "[Epoch 10/20] [Batch 90/92] [D loss: 0.7294559478759766] [G loss: 1.29833984375]\n",
      "saved images and state\n",
      "[Epoch 11/20] [Batch 0/92] [D loss: 0.5479233264923096] [G loss: 2.1906728744506836]\n",
      "saved images and state\n",
      "[Epoch 11/20] [Batch 10/92] [D loss: 0.5626871585845947] [G loss: 1.93850839138031]\n",
      "saved images and state\n",
      "[Epoch 11/20] [Batch 20/92] [D loss: 0.7728919982910156] [G loss: 1.4851043224334717]\n",
      "saved images and state\n",
      "[Epoch 11/20] [Batch 30/92] [D loss: 0.5392960906028748] [G loss: 1.904879093170166]\n",
      "saved images and state\n",
      "[Epoch 11/20] [Batch 40/92] [D loss: 0.580401599407196] [G loss: 2.110064744949341]\n",
      "saved images and state\n",
      "[Epoch 11/20] [Batch 50/92] [D loss: 0.581821620464325] [G loss: 1.5142287015914917]\n",
      "saved images and state\n",
      "[Epoch 11/20] [Batch 60/92] [D loss: 0.6945858001708984] [G loss: 1.734521746635437]\n",
      "saved images and state\n",
      "[Epoch 11/20] [Batch 70/92] [D loss: 0.6576544046401978] [G loss: 1.3995258808135986]\n",
      "saved images and state\n",
      "[Epoch 11/20] [Batch 80/92] [D loss: 0.4955883026123047] [G loss: 2.086576461791992]\n",
      "saved images and state\n",
      "[Epoch 11/20] [Batch 90/92] [D loss: 0.6367700099945068] [G loss: 1.3314210176467896]\n",
      "saved images and state\n",
      "[Epoch 12/20] [Batch 0/92] [D loss: 0.5905047655105591] [G loss: 1.586517095565796]\n",
      "saved images and state\n",
      "[Epoch 12/20] [Batch 10/92] [D loss: 0.814736008644104] [G loss: 1.4658409357070923]\n",
      "saved images and state\n",
      "[Epoch 12/20] [Batch 20/92] [D loss: 0.6914359331130981] [G loss: 1.8855516910552979]\n",
      "saved images and state\n",
      "[Epoch 12/20] [Batch 30/92] [D loss: 0.7634250521659851] [G loss: 1.5695202350616455]\n",
      "saved images and state\n",
      "[Epoch 12/20] [Batch 40/92] [D loss: 0.5295989513397217] [G loss: 2.20580792427063]\n",
      "saved images and state\n",
      "[Epoch 12/20] [Batch 50/92] [D loss: 0.5536262392997742] [G loss: 1.5293943881988525]\n",
      "saved images and state\n",
      "[Epoch 12/20] [Batch 60/92] [D loss: 0.4718480110168457] [G loss: 2.1623730659484863]\n",
      "saved images and state\n",
      "[Epoch 12/20] [Batch 70/92] [D loss: 0.4839516580104828] [G loss: 2.216853141784668]\n",
      "saved images and state\n",
      "[Epoch 12/20] [Batch 80/92] [D loss: 0.5125479698181152] [G loss: 2.3188889026641846]\n",
      "saved images and state\n",
      "[Epoch 12/20] [Batch 90/92] [D loss: 0.6334152817726135] [G loss: 2.0927422046661377]\n",
      "saved images and state\n",
      "[Epoch 13/20] [Batch 0/92] [D loss: 0.48008042573928833] [G loss: 1.8105815649032593]\n",
      "saved images and state\n",
      "[Epoch 13/20] [Batch 10/92] [D loss: 0.6062322854995728] [G loss: 1.6335153579711914]\n",
      "saved images and state\n",
      "[Epoch 13/20] [Batch 20/92] [D loss: 0.6459627151489258] [G loss: 1.7793183326721191]\n",
      "saved images and state\n",
      "[Epoch 13/20] [Batch 30/92] [D loss: 0.5315405130386353] [G loss: 2.321552038192749]\n",
      "saved images and state\n",
      "[Epoch 13/20] [Batch 40/92] [D loss: 0.619539737701416] [G loss: 2.1047117710113525]\n",
      "saved images and state\n",
      "[Epoch 13/20] [Batch 50/92] [D loss: 0.608666181564331] [G loss: 2.3266751766204834]\n",
      "saved images and state\n",
      "[Epoch 13/20] [Batch 60/92] [D loss: 0.5893036127090454] [G loss: 1.5903077125549316]\n",
      "saved images and state\n",
      "[Epoch 13/20] [Batch 70/92] [D loss: 0.5613530278205872] [G loss: 1.8113491535186768]\n",
      "saved images and state\n",
      "[Epoch 13/20] [Batch 80/92] [D loss: 0.4184308648109436] [G loss: 1.9139418601989746]\n",
      "saved images and state\n",
      "[Epoch 13/20] [Batch 90/92] [D loss: 0.6005745530128479] [G loss: 1.502867579460144]\n",
      "saved images and state\n",
      "[Epoch 14/20] [Batch 0/92] [D loss: 0.6499226093292236] [G loss: 1.9195091724395752]\n",
      "saved images and state\n",
      "[Epoch 14/20] [Batch 10/92] [D loss: 0.6435357332229614] [G loss: 1.6058218479156494]\n",
      "saved images and state\n",
      "[Epoch 14/20] [Batch 20/92] [D loss: 0.46475285291671753] [G loss: 2.080500602722168]\n",
      "saved images and state\n",
      "[Epoch 14/20] [Batch 30/92] [D loss: 0.6595287322998047] [G loss: 1.3005720376968384]\n",
      "saved images and state\n",
      "[Epoch 14/20] [Batch 40/92] [D loss: 0.6261379718780518] [G loss: 1.8206532001495361]\n",
      "saved images and state\n",
      "[Epoch 14/20] [Batch 50/92] [D loss: 0.5523157119750977] [G loss: 1.9838440418243408]\n",
      "saved images and state\n",
      "[Epoch 14/20] [Batch 60/92] [D loss: 0.6114512085914612] [G loss: 2.407195568084717]\n",
      "saved images and state\n",
      "[Epoch 14/20] [Batch 70/92] [D loss: 0.5497507452964783] [G loss: 1.617995023727417]\n",
      "saved images and state\n",
      "[Epoch 14/20] [Batch 80/92] [D loss: 0.5454712510108948] [G loss: 1.8535946607589722]\n",
      "saved images and state\n",
      "[Epoch 14/20] [Batch 90/92] [D loss: 0.7840510010719299] [G loss: 1.1792899370193481]\n",
      "saved images and state\n",
      "[Epoch 15/20] [Batch 0/92] [D loss: 0.5000183582305908] [G loss: 2.092862606048584]\n",
      "saved images and state\n",
      "[Epoch 15/20] [Batch 10/92] [D loss: 0.484829306602478] [G loss: 1.9763857126235962]\n",
      "saved images and state\n",
      "[Epoch 15/20] [Batch 20/92] [D loss: 0.5380923748016357] [G loss: 2.0282864570617676]\n",
      "saved images and state\n",
      "[Epoch 15/20] [Batch 30/92] [D loss: 0.5402786135673523] [G loss: 2.020444393157959]\n",
      "saved images and state\n",
      "[Epoch 15/20] [Batch 40/92] [D loss: 0.45431870222091675] [G loss: 2.1333107948303223]\n",
      "saved images and state\n",
      "[Epoch 15/20] [Batch 50/92] [D loss: 0.4660260081291199] [G loss: 2.89686918258667]\n",
      "saved images and state\n",
      "[Epoch 15/20] [Batch 60/92] [D loss: 0.3995143175125122] [G loss: 2.1042513847351074]\n",
      "saved images and state\n",
      "[Epoch 15/20] [Batch 70/92] [D loss: 0.6493115425109863] [G loss: 1.4579706192016602]\n",
      "saved images and state\n",
      "[Epoch 15/20] [Batch 80/92] [D loss: 0.46759033203125] [G loss: 2.0743584632873535]\n",
      "saved images and state\n",
      "[Epoch 15/20] [Batch 90/92] [D loss: 0.46580970287323] [G loss: 2.6055710315704346]\n",
      "saved images and state\n",
      "[Epoch 16/20] [Batch 0/92] [D loss: 0.4459773898124695] [G loss: 2.2196264266967773]\n",
      "saved images and state\n",
      "[Epoch 16/20] [Batch 10/92] [D loss: 0.4746064245700836] [G loss: 2.0497922897338867]\n",
      "saved images and state\n",
      "[Epoch 16/20] [Batch 20/92] [D loss: 0.5654225945472717] [G loss: 1.9546840190887451]\n",
      "saved images and state\n",
      "[Epoch 16/20] [Batch 30/92] [D loss: 0.4553356170654297] [G loss: 2.664125919342041]\n",
      "saved images and state\n",
      "[Epoch 16/20] [Batch 40/92] [D loss: 0.47618749737739563] [G loss: 2.2301201820373535]\n",
      "saved images and state\n",
      "[Epoch 16/20] [Batch 50/92] [D loss: 0.6411296129226685] [G loss: 2.598255157470703]\n",
      "saved images and state\n",
      "[Epoch 16/20] [Batch 60/92] [D loss: 0.5220068693161011] [G loss: 1.9913685321807861]\n",
      "saved images and state\n",
      "[Epoch 16/20] [Batch 70/92] [D loss: 0.5785424113273621] [G loss: 2.1737117767333984]\n",
      "saved images and state\n",
      "[Epoch 16/20] [Batch 80/92] [D loss: 0.5127301216125488] [G loss: 1.4878768920898438]\n",
      "saved images and state\n",
      "[Epoch 16/20] [Batch 90/92] [D loss: 0.7225952744483948] [G loss: 1.7756534814834595]\n",
      "saved images and state\n",
      "[Epoch 17/20] [Batch 0/92] [D loss: 0.4819420278072357] [G loss: 2.428278684616089]\n",
      "saved images and state\n",
      "[Epoch 17/20] [Batch 10/92] [D loss: 0.6434553265571594] [G loss: 1.5737699270248413]\n",
      "saved images and state\n",
      "[Epoch 17/20] [Batch 20/92] [D loss: 0.5483368039131165] [G loss: 2.364396095275879]\n",
      "saved images and state\n",
      "[Epoch 17/20] [Batch 30/92] [D loss: 0.5643912553787231] [G loss: 2.1170458793640137]\n",
      "saved images and state\n",
      "[Epoch 17/20] [Batch 40/92] [D loss: 0.44262611865997314] [G loss: 2.4309256076812744]\n",
      "saved images and state\n",
      "[Epoch 17/20] [Batch 50/92] [D loss: 0.33914798498153687] [G loss: 2.466369867324829]\n",
      "saved images and state\n",
      "[Epoch 17/20] [Batch 60/92] [D loss: 0.5134837031364441] [G loss: 1.7335306406021118]\n",
      "saved images and state\n",
      "[Epoch 17/20] [Batch 70/92] [D loss: 0.4927169978618622] [G loss: 2.026675224304199]\n",
      "saved images and state\n",
      "[Epoch 17/20] [Batch 80/92] [D loss: 0.49715137481689453] [G loss: 1.7647037506103516]\n",
      "saved images and state\n",
      "[Epoch 17/20] [Batch 90/92] [D loss: 0.50614994764328] [G loss: 2.10060453414917]\n",
      "saved images and state\n",
      "[Epoch 18/20] [Batch 0/92] [D loss: 0.4205855131149292] [G loss: 2.2026073932647705]\n",
      "saved images and state\n",
      "[Epoch 18/20] [Batch 10/92] [D loss: 0.5133002400398254] [G loss: 2.0354185104370117]\n",
      "saved images and state\n",
      "[Epoch 18/20] [Batch 20/92] [D loss: 0.4614816904067993] [G loss: 2.35229229927063]\n",
      "saved images and state\n",
      "[Epoch 18/20] [Batch 30/92] [D loss: 0.33449438214302063] [G loss: 2.3116490840911865]\n",
      "saved images and state\n",
      "[Epoch 18/20] [Batch 40/92] [D loss: 0.42112022638320923] [G loss: 2.4784913063049316]\n",
      "saved images and state\n",
      "[Epoch 18/20] [Batch 50/92] [D loss: 0.5118642449378967] [G loss: 1.6719536781311035]\n",
      "saved images and state\n",
      "[Epoch 18/20] [Batch 60/92] [D loss: 0.5207659006118774] [G loss: 1.800498366355896]\n",
      "saved images and state\n",
      "[Epoch 18/20] [Batch 70/92] [D loss: 0.29881036281585693] [G loss: 2.744448661804199]\n",
      "saved images and state\n",
      "[Epoch 18/20] [Batch 80/92] [D loss: 0.465611070394516] [G loss: 2.215471029281616]\n",
      "saved images and state\n",
      "[Epoch 18/20] [Batch 90/92] [D loss: 0.39357882738113403] [G loss: 2.2764010429382324]\n",
      "saved images and state\n",
      "[Epoch 19/20] [Batch 0/92] [D loss: 0.5636340975761414] [G loss: 2.9094109535217285]\n",
      "saved images and state\n",
      "[Epoch 19/20] [Batch 10/92] [D loss: 0.6707330346107483] [G loss: 2.239157199859619]\n",
      "saved images and state\n",
      "[Epoch 19/20] [Batch 20/92] [D loss: 0.4011828899383545] [G loss: 2.4815673828125]\n",
      "saved images and state\n",
      "[Epoch 19/20] [Batch 30/92] [D loss: 0.5437592267990112] [G loss: 2.994903564453125]\n",
      "saved images and state\n",
      "[Epoch 19/20] [Batch 40/92] [D loss: 0.49297064542770386] [G loss: 2.235063076019287]\n",
      "saved images and state\n",
      "[Epoch 19/20] [Batch 50/92] [D loss: 0.4730963110923767] [G loss: 1.8499383926391602]\n",
      "saved images and state\n",
      "[Epoch 19/20] [Batch 60/92] [D loss: 0.4678473472595215] [G loss: 2.2119243144989014]\n",
      "saved images and state\n",
      "[Epoch 19/20] [Batch 70/92] [D loss: 0.37642616033554077] [G loss: 2.2347805500030518]\n",
      "saved images and state\n",
      "[Epoch 19/20] [Batch 80/92] [D loss: 0.3185076415538788] [G loss: 2.723858594894409]\n",
      "saved images and state\n",
      "[Epoch 19/20] [Batch 90/92] [D loss: 0.5121758580207825] [G loss: 2.514517307281494]\n",
      "saved images and state\n"
     ]
    }
   ],
   "source": [
    "D_train_loss_saving = []\n",
    "G_train_loss_saving = []\n",
    "\n",
    "\n",
    "for epoch in range(epoch_size):\n",
    "    for batch_index, (real_image, _) in enumerate(train_loader):\n",
    "\n",
    "        # ---------------- Update Discriminator, Fixed Generator ----------------\n",
    "\n",
    "        opt_D.zero_grad()\n",
    "\n",
    "        # create real & fake images, then discriminate them\n",
    "        real_image = real_image.to(device)               # (batch_size, 1, image_size[0], image_size[1])\n",
    "        output_real_after_sigmoid = discriminator(real_image) \n",
    "        output_real = output_real_after_sigmoid.view(-1) # (batch_size, 1, 1) --- view(-1) ---> (batch_size,)\n",
    "\n",
    "        noise = torch.randn(batch_size, latent_dim, 1, 1, device=device).to(device)\n",
    "        fake_image, tensor_beforeTanh_BN, fake_tensor_afterBN = generator(noise)\n",
    "        output_fake_after_sigmoid = discriminator(fake_image.detach())\n",
    "        output_fake = output_fake_after_sigmoid.view(-1)\n",
    "\n",
    "        # compute the loss of output_real with real_label & output_fake with fake_label\n",
    "        loss_real = criterion(output_real, real_label)\n",
    "        loss_fake = criterion(output_fake, fake_label)\n",
    "\n",
    "\n",
    "        loss_real.backward()\n",
    "        loss_fake.backward()\n",
    "\n",
    "        loss_D = loss_real + loss_fake\n",
    "\n",
    "        opt_D.step()\n",
    "\n",
    "        # ---------------- Update Generator, Fixed Discriminator ----------------\n",
    "\n",
    "        opt_G.zero_grad()\n",
    "\n",
    "        # create fake images, then discriminate them\n",
    "        output_fake_after_sigmoid = discriminator(fake_image)\n",
    "        output_fake = output_fake_after_sigmoid.view(-1)\n",
    "\n",
    "        # compute the loss of output_fake with real_label\n",
    "        loss_G = criterion(output_fake, real_label)\n",
    "\n",
    "        loss_G.backward()\n",
    "\n",
    "        opt_G.step()\n",
    "\n",
    "        if batch_index % 10 == 0:\n",
    "            print(f\"[Epoch {epoch}/{epoch_size}] [Batch {batch_index}/{len(train_loader)}] [D loss: {loss_D.item()}] [G loss: {loss_G.item()}]\")\n",
    "\n",
    "            D_train_loss_saving.append(loss_D.item())\n",
    "            G_train_loss_saving.append(loss_G.item())\n",
    "\n",
    "            fixed_image, fake_tensor_beforeTanh_BN, fake_tensor_afterBN  = generator(fixed_noise)\n",
    "\n",
    "\n",
    "\n",
    "            save_image(fixed_image, os.path.join(image_file, '{0}_{1}.png'.format(epoch,batch_index)), nrow=8, normalize=True)\n",
    "\n",
    "\n",
    "            torch.save(discriminator.state_dict(), os.path.join(ckpt_file, 'discriminator_{0}_{1}.pt'.format(epoch,batch_index)))\n",
    "            torch.save(generator.state_dict(), os.path.join(ckpt_file, 'generator_{0}_{1}.pt'.format(epoch,batch_index)))\n",
    "\n",
    "\n",
    "            torch.save(output_real_after_sigmoid, os.path.join(discriminator_tensor, 'output_real_after_sigmoid_{0}_{1}.pt'.format(epoch,batch_index)))\n",
    "            torch.save(output_fake_after_sigmoid, os.path.join(discriminator_tensor, 'output_fake_after_sigmoid_{0}_{1}.pt'.format(epoch,batch_index)))\n",
    "\n",
    "\n",
    "            torch.save(fake_tensor_beforeTanh_BN, os.path.join(generator_tensor, 'fake_tensor_beforeTanh_BN_{0}_{1}.pt'.format(epoch,batch_index)))\n",
    "            torch.save(fake_tensor_afterBN, os.path.join(generator_tensor, 'fake_tensor_afterBN_{0}_{1}.pt'.format(epoch,batch_index)))\n",
    "            torch.save(fixed_image, os.path.join(generator_tensor, 'fake_tensor_afterTanh_{0}_{1}.pt'.format(epoch,batch_index)))\n",
    "            \n",
    "\n",
    "            print(\"saved images and state\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83f0457d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deeper Structure\n",
    "# Run ??-hr/2787-min on mac mini (now)\n",
    "# 17-min 10-batch (now)\n",
    "# 11/6 17:34 ~ 11/9 15:58 \n",
    "\n",
    "torch.save(D_train_loss_saving, os.path.join(ckpt_file, 'D_train_loss_saving.pt'))\n",
    "torch.save(G_train_loss_saving, os.path.join(ckpt_file, 'G_train_loss_saving.pt'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
